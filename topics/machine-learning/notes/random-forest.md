# 🌲 랜덤 포레스트 앙상블 기법 & 부트스트래핑 (Random Forest & Bootstrapping)

랜덤 포레스트는 여러 개의 결정 트리를 **배깅(Bagging)** 방식으로 결합한 강력한 앙상블 모델이며, 부트스트래핑(bootstrap sampling)을 통해 다양한 학습 세트를 생성합니다.

---

## 🎯 앙상블 기법 개요

- **앙상블(Ensemble)**: 여러 모델의 예측을 결합해 단일 모델보다 성능·안정성↑  
- 주요 방식:  
  - **배깅(Bagging)**: 독립적 학습 후 평균·다수결 결합  
  - **부스팅(Boosting)**: 순차적 학습, 이전 오류 보정  
  - **스태킹(Stacking)**: 2단계 이상 모델 조합  

---

## 1️⃣ 배깅(Bagging)

### 📌 정의  
Bootstrap AGGregatING의 약자로, 여러 학습기(base learner)를 **병렬**로 학습시켜 결과를 결합.

### 🛠️ 절차

1. **부트스트랩 샘플링**  
   - 전체 데이터 \(D\)에서 크기 \(n\)인 샘플을 복원추출로 \(T\)번 생성 → \(D_1, …, D_T\)  
2. **모델 학습**  
   - 각 부트스트랩 샘플 \(D_t\)에 동일한 알고리즘(예: 결정 트리) 학습  
3. **결과 결합**  
   - 분류: 다수결 투표  
   - 회귀: 평균 예측

### ✅ 장점 / ❌ 단점

| 장점                                         | 단점                                 |
|----------------------------------------------|--------------------------------------|
| 과적합 감소 → 분산(Variance) 낮춤            | 계산·메모리 비용 증가                |
| 노이즈·이상치에 강건                         | 서로 다른 모델 종류 조합 불가        |
| OOB(Out-Of-Bag) 평가 바로 사용 가능          | 해석력(모델 내부 구조) 감소         |

---

## 2️⃣ 랜덤 포레스트(Random Forest)

### 📌 정의  
배깅된 결정 트리에 “특성 무작위 선택(Random Feature Selection)”을 추가해 트리 간 상관성을 줄인 모델.

### 🛠️ 절차

1. 부트스트랩 샘플 \(D_t\) 생성  
2. 트리 학습 시 **각 노드 분할**마다 전체 피처 중 **\(\sqrt{p}\) (분류)** 또는 **\(p/3\) (회귀)** 개 랜덤 샘플링  
3. 최적 분할 기준(엔트로피·지니 등) 적용해 분할  
4. T개의 트리 학습 후 예측 집계

### ✅ 장점 / ❌ 단점

| 장점                                               | 단점                                    |
|----------------------------------------------------|-----------------------------------------|
| 배깅보다 상관도↓ → 추가적 성능·안정성 향상          | 대규모 트리 수 시 예측 속도 느려짐      |
| 고차원·다중 클래스 문제에 강건                     | 오버헤드(메모리·저장공간) 큼            |
| 피처 중요도(feature importance) 제공               | 하이퍼파라미터(trees, depth) 튜닝 필요 |

---

## 3️⃣ 부트스트래핑(Bootstrapping)

### 📌 정의  
원본 데이터에서 **복원 추출(resampling with replacement)** 방식으로 랜덤 샘플 생성.

### 🔍 특징

- 각 부트스트랩 샘플은 약 \(63.2\%\)의 고유 샘플 포함  
- 남은 \(36.8\%\) 데이터는 **OOB 샘플**로, 모델 평가·성능 검증에 활용

---

## 4️⃣ OOB 평가(Out-Of-Bag)

### 📌 정의  
부트스트랩 샘플링에서 제외된 데이터(OOB 샘플)를 이용해 추가 검증 없이 **내부 검증** 수행.

\[
\hat y_i^\text{OOB} = \text{aggregate}\bigl\{\,\hat y_i^{(t)}: x_i \notin D_t \bigr\}
\]

- 분류: 다수결 투표  
- 회귀: 평균  

### 💡 장점  
- 교차검증 불필요 → 학습 비용 절감  
- 과적합 모니터링에 유용

---

## 5️⃣ 주요 하이퍼파라미터 & 실무 팁

| 하이퍼파라미터        | 역할                                       | 권장 설정·팁                            |
|-----------------------|--------------------------------------------|----------------------------------------|
| `n_estimators`        | 트리 개수                                   | 100~500 이상, 성능 포화점 관찰         |
| `max_depth`           | 최대 트리 깊이                              | 과적합 방지 위해  None 또는 10~20 지정 |
| `max_features`        | 분할 시 사용할 피처 개수                    | 분류: √p, 회귀: p/3 기본               |
| `min_samples_split`   | 분할 위한 최소 샘플 수                      | 2~10, 데이터 크기·잡음 수준 고려       |
| `min_samples_leaf`    | 리프 노드 최소 샘플 수                      | 1~5, 과적합 경향 낮추려면 증가         |
| `bootstrap`           | 부트스트랩 사용 여부                        | 기본 `True` 유지                       |

---

## 💡 실무 팁 요약

1. **`n_estimators`** 늘리면 안정성↑·속도↓ → 병렬화 활용  
2. **`max_features`** 조정으로 편향-분산 트레이드오프 최적화  
3. **OOB score**로 빠른 성능 모니터링  
4. **피처 중요도** 활용해 중요 변수 선별·차원 축소  
5. **불균형 데이터**: `class_weight='balanced'` 또는 `sample_weight` 사용  
