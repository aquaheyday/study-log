# 🔍 서포트 벡터 머신 (SVM) — 초평면 개념 & 커널 트릭

SVM은 **초평면(Hyperplane)** 을 통해 데이터를 분리하고, **커널 트릭(Kernel Trick)** 으로 비선형 경계도 학습 가능한 강력한 분류 알고리즘입니다.

---

## 🛠️ 초평면(Hyperplane) 개념

### 📌 정의  
- \(p\)-차원 공간에서 \((p-1)\)-차원 평면으로, 이진 분류 시 두 클래스 사이를 구분하는 결정 경계  
- 방정식:  
  \[
  \mathbf{w}^\top \mathbf{x} + b = 0
  \]  
  - \(\mathbf{w}\): 법선 벡터(normal vector)  
  - \(b\): 편향(bias, intercept)

### 🔍 마진(Margin)  
- **서포트 벡터**: 초평면에 가장 가까운 훈련 샘플  
- **마진**: 양쪽 클래스 서포트 벡터까지의 거리 합 (여유 공간)  
  \[
  \text{Margin} = \frac{2}{\|\mathbf{w}\|}
  \]  
- **목표**: 마진 최대화 → 일반화 성능 향상  

### 🔧 최적화 문제 (Hard-Margin)  
\[
\begin{aligned}
\min_{\mathbf{w},b} \quad & \frac{1}{2}\|\mathbf{w}\|^2 \\
\text{s.t.} \quad & y_i(\mathbf{w}^\top \mathbf{x}_i + b) \ge 1, \quad i=1,\dots,n
\end{aligned}
\]

### 🚦 소프트 마진 (Soft-Margin)  
- 노이즈·중첩 클래스 허용 위해 슬랙 변수 \(\xi_i\) 도입  
\[
\begin{aligned}
\min_{\mathbf{w},b,\boldsymbol\xi} \quad & \frac{1}{2}\|\mathbf{w}\|^2 + C\sum_i \xi_i \\
\text{s.t.} \quad & y_i(\mathbf{w}^\top \mathbf{x}_i + b) \ge 1 - \xi_i,\;\; \xi_i \ge 0
\end{aligned}
\]  
- \(C\): 규제 파라미터 (슬랙 벌점 크기 조절)

---

## 🌐 커널 트릭 (Kernel Trick)

### 📌 정의  
저차원에서 비선형 분리가 어려울 때, **고차원 특징 공간**으로 매핑한 뒤 초평면으로 선형 분류.  
직접 매핑하지 않고 **커널 함수**로 내적을 계산해 연산 비용 절감.

### 🔑 커널 함수 예시

| 커널 유형                | 수식                                                             | 특징                                 |
|--------------------------|------------------------------------------------------------------|--------------------------------------|
| **선형 커널 (Linear)**   | \(K(\mathbf{x},\mathbf{z}) = \mathbf{x}^\top \mathbf{z}\)         | 고차원 매핑 없이 기본 SVM            |
| **다항 커널 (Poly)**     | \(K(\mathbf{x},\mathbf{z}) = (\gamma\,\mathbf{x}^\top\mathbf{z} + r)^d\) | 차수 \(d\)로 비선형성 조절           |
| **RBF 커널 (Gaussian)**  | \(K(\mathbf{x},\mathbf{z}) = \exp\bigl(-\gamma\|\mathbf{x}-\mathbf{z}\|^2\bigr)\) | 국소적 영향, \(\gamma\)로 폭 조정     |
| **시그모이드 커널**      | \(K(\mathbf{x},\mathbf{z}) = \tanh(\gamma\,\mathbf{x}^\top\mathbf{z} + r)\) | 신경망 유사, 제한된 사용               |

- \(\gamma, r, d\) 등 하이퍼파라미터는 교차검증으로 최적화

### 🛠️ 이점 & 한계

| 장점                                                      | 단점                                               |
|-----------------------------------------------------------|----------------------------------------------------|
| 복잡한 비선형 경계도 커널로 효과적 분류                    | 큰 데이터·고차원 시 계산·메모리 부담              |
| 고차원 매핑을 암시적으로 처리 → 계산 효율적               | 커널 선택·파라미터 튜닝 민감                       |
| 마진 최대화로 일반화 성능 우수                           | 대용량 데이터셋, 스케일링·특성 선택 사전 처리 중요 |

---

## 💡 실무 팁 요약

1. **데이터 스케일링**: SVM은 거리 기반 → `StandardScaler` 필수  
2. **커널 선택**:  
   - 선형 분리 가능 시: **선형 커널** 빠른 학습  
   - 비선형: **RBF**(일반적), **Poly**(다항 관계)  
3. **하이퍼파라미터 튜닝**: GridSearchCV로 `C`, `gamma`, `degree` 최적화  
4. **소프트 마진**: `C` 값 크게 → 과적합↑, 작게 → 언더핏↑  
5. **대규모 데이터**: 전처리 후 **샘플링** 또는 **근사 SVM**(LIBLINEAR, SGD) 고려  
