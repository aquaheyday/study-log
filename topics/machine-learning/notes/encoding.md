# 📊 범주형 인코딩 (Categorical Encoding)

데이터 전처리 단계에서 **범주형 변수**를 수치형으로 변환하는 것은 머신러닝 모델이 처리할 수 있도록 하는 필수 작업입니다.

---

## 🏷️ 레이블 인코딩 (Label Encoding)

### 📌 정의  
범주형 값을 0부터 시작하는 정수로 매핑하여 수치형으로 변환.  
예: `["Red", "Green", "Blue", "Green"] → [2, 1, 0, 1]`

### 🛠️ 처리 방법

| 단계 | 설명 |
|------|------|
| 1. 고유 값 추출 | 범주형 변수의 고유 카테고리 목록 생성 |
| 2. 정수 매핑 | 각 카테고리에 0, 1, 2… 순서대로 정수 부여 |
| 3. 치환 | 원본 값을 매핑된 정수로 대체 |

### ✅ 장점 / ❌ 단점

| 장점 | 단점 |
|------|------|
| 메모리·시간 효율적 | 모델이 값의 순서(ordinal)를 학습할 수 있어 잘못된 순서 가정 위험 |
| 구현이 간단 | 카테고리 개수가 많으면 정수 간 거리 해석 문제 |

### 💡 실무 팁
- 범주 간 순서가 **명확한** 경우(예: Small, Medium, Large)에 사용 권장  
- 순서가 없는 범주에는 주의, 트리 계열 모델에는 큰 문제 없으나 선형 모델·거리 기반 모델에는 부적합  

---

## 🆓 원-핫 인코딩 (One-Hot Encoding)

### 📌 정의  
각 카테고리를 새로운 이진(0/1) 피처로 분리하여 표현.  
예: `["Red", "Green", "Blue"] → [[1,0,0], [0,1,0], [0,0,1]]`

### 🛠️ 처리 방법

| 단계 | 설명 |
|------|------|
| 1. 고유 값 추출 | 범주형 변수의 고유 카테고리 목록 생성 |
| 2. 피처 생성 | 각 카테고리마다 새로운 이진 피처(column) 생성 |
| 3. 인코딩 | 해당 카테고리에만 1, 나머지는 0으로 채움 |

### ✅ 장점 / ❌ 단점

| 장점 | 단점 |
|------|------|
| 순서 가정 없이 안전 | 차원 폭발(Curse of Dimensionality) 발생 가능 |
| 대부분의 모델에 무난히 적용 | 고유 값 수가 많으면 메모리·계산량 증가 |

### 💡 실무 팁
- 카디널리티(고유 값 개수)가 **작은** 변수에 우선 적용  
- 고유 값이 많은 경우 `Hashing Encoding`, `Target Encoding` 등 대체 기법 고려  
- `drop='first'` 옵션으로 다중공선성(Multicollinearity) 완화 가능 (scikit-learn 기준)

---

## 🧠 실무 팁 요약

- **순서 정보**가 있으면 → 레이블 인코딩  
- **순서 정보**가 없으면 → 원-핫 인코딩 (단, 카디널리티 주의)  
- 고유 값이 너무 많으면 → 해싱·빈도 기반·목표 인코딩 등 고려  
- 인코딩 후 **피처 중요도**나 **모델 성능**을 검토하여 최적 기법 선택  

